{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c96e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille train : (73113, 43)\n",
      "Taille test : (30997, 43)\n",
      "Distribution train : fire\n",
      "0    0.801554\n",
      "1    0.198446\n",
      "Name: proportion, dtype: float64\n",
      "Distribution test : fire\n",
      "0    0.796335\n",
      "1    0.203665\n",
      "Name: proportion, dtype: float64\n",
      "Accuracy : 0.9748362744781753\n",
      "\n",
      "Classification report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98     24684\n",
      "           1       0.93      0.95      0.94      6313\n",
      "\n",
      "    accuracy                           0.97     30997\n",
      "   macro avg       0.96      0.97      0.96     30997\n",
      "weighted avg       0.98      0.97      0.97     30997\n",
      "\n",
      "\n",
      "Confusion matrix :\n",
      " [[24204   480]\n",
      " [  300  6013]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "file = r\"C:\\Users\\DELL\\Desktop\\project_fire\\data\\processed\\fire_soil_balanced.csv\"\n",
    "\n",
    "chunksize = 500000  # nombre de lignes par chunk\n",
    "train_parts = []\n",
    "test_parts = []\n",
    "\n",
    "# --- Lecture et traitement chunk par chunk ---\n",
    "for chunk in pd.read_csv(file, chunksize=chunksize):\n",
    "    # Suppression de geometry si existe\n",
    "    if \"geometry\" in chunk.columns:\n",
    "        chunk = chunk.drop(columns=[\"geometry\"])\n",
    "\n",
    "    # Séparer X / y\n",
    "    X = chunk.drop(columns=['fire'])\n",
    "    y = chunk['fire']\n",
    "\n",
    "    # Encodage One-Hot pour les colonnes catégorielles\n",
    "    cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    if len(cat_cols) > 0:\n",
    "        X = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
    "\n",
    "    # Reconstituer chunk preprocessé\n",
    "    processed = pd.concat([X, y], axis=1)\n",
    "\n",
    "    # Split 70% train / 30% test\n",
    "    mask = np.random.rand(len(processed)) < 0.7\n",
    "    train_parts.append(processed[mask])\n",
    "    test_parts.append(processed[~mask])\n",
    "\n",
    "# --- Concaténer tous les chunks ---\n",
    "train_df = pd.concat(train_parts, ignore_index=True)\n",
    "test_df = pd.concat(test_parts, ignore_index=True)\n",
    "\n",
    "print(\"Taille train :\", train_df.shape)\n",
    "print(\"Taille test :\", test_df.shape)\n",
    "print(\"Distribution train :\", train_df['fire'].value_counts(normalize=True))\n",
    "print(\"Distribution test :\", test_df['fire'].value_counts(normalize=True))\n",
    "\n",
    "# --- Séparer features / target ---\n",
    "X_train = train_df.drop(columns=['fire'])\n",
    "y_train = train_df['fire']\n",
    "X_test = test_df.drop(columns=['fire'])\n",
    "y_test = test_df['fire']\n",
    "\n",
    "# --- Random Forest ---\n",
    "rf_model = RandomForestClassifier(n_estimators=200, max_depth=20, n_jobs=-1, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# --- Évaluation ---\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification report :\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion matrix :\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9dc6714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sur le training set : 0.9985228345164334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# --- Accuracy sur le training set ---\n",
    "y_train_pred = rf_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Accuracy sur le training set :\", train_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "173cecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class RandomForestScratch:\n",
    "\n",
    "    def __init__(self, n_trees=10, max_depth=5, min_samples_split=2, max_features=None):\n",
    "        \"\"\"\n",
    "        n_trees : nombre d'arbres\n",
    "        max_depth : profondeur max des arbres\n",
    "        min_samples_split : min de samples pour splitter\n",
    "        max_features : nombre de variables choisies aléatoirement à chaque split\n",
    "        \"\"\"\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_features = max_features\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        for i in range(self.n_trees):\n",
    "            # --- 1) Tirage bootstrap : on prend N échantillons avec remise\n",
    "            idx = np.random.choice(n_samples, n_samples, replace=True)\n",
    "            X_sample = X[idx]\n",
    "            y_sample = y[idx]\n",
    "\n",
    "            # --- 2) Créer un arbre\n",
    "            tree = DecisionTreeScratch(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split\n",
    "            )\n",
    "\n",
    "            # --- 3) Entraîner l'arbre\n",
    "            tree.fit(X_sample, y_sample)\n",
    "\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Chaque arbre prédit\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "\n",
    "        # Vote majoritaire\n",
    "        final_pred = []\n",
    "        for sample_preds in tree_preds.T:\n",
    "            vote = Counter(sample_preds).most_common(1)[0][0]\n",
    "            final_pred.append(vote)\n",
    "\n",
    "        return np.array(final_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59404722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15324\\2340403211.py:12: DtypeWarning: Columns (0,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file, chunksize=chunksize):\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.58 GiB for an array with shape (500000, 11983) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m cat_cols \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cat_cols) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 24\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Reconstituer chunk\u001b[39;00m\n\u001b[0;32m     27\u001b[0m processed \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([X, y], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\encoding.py:215\u001b[0m, in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    211\u001b[0m     with_dummies \u001b[38;5;241m=\u001b[39m [data\u001b[38;5;241m.\u001b[39mselect_dtypes(exclude\u001b[38;5;241m=\u001b[39mdtypes_to_encode)]\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col, pre, sep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(data_to_encode\u001b[38;5;241m.\u001b[39mitems(), prefix, prefix_sep):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# col is (column_name, column), use just column data here\u001b[39;00m\n\u001b[1;32m--> 215\u001b[0m     dummy \u001b[38;5;241m=\u001b[39m \u001b[43m_get_dummies_1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprefix_sep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdummy_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdummy_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m     with_dummies\u001b[38;5;241m.\u001b[39mappend(dummy)\n\u001b[0;32m    225\u001b[0m result \u001b[38;5;241m=\u001b[39m concat(with_dummies, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\encoding.py:354\u001b[0m, in \u001b[0;36m_get_dummies_1d\u001b[1;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    353\u001b[0m     dummy_dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_\n\u001b[1;32m--> 354\u001b[0m dummy_mat \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdummy_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mF\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m dummy_mat[np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(codes)), codes] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dummy_na:\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;66;03m# reset NaN GH4446\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.58 GiB for an array with shape (500000, 11983) and data type bool"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "file = r\"C:\\Users\\DELL\\Desktop\\project_fire\\data\\processed\\fire_soil_merged_cleaned.csv\"\n",
    "\n",
    "chunksize = 500000\n",
    "train_parts = []\n",
    "test_parts = []\n",
    "\n",
    "# --- Lecture et préprocessing chunk par chunk ---\n",
    "for chunk in pd.read_csv(file, chunksize=chunksize):\n",
    "    # Supprimer geometry si existante\n",
    "    if \"geometry\" in chunk.columns:\n",
    "        chunk = chunk.drop(columns=[\"geometry\"])\n",
    "    \n",
    "    # Séparer X / y\n",
    "    X = chunk.drop(columns=[\"fire\"])\n",
    "    y = chunk[\"fire\"]\n",
    "    \n",
    "    # Encodage One-Hot des colonnes catégorielles\n",
    "    cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "    if len(cat_cols) > 0:\n",
    "        X = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
    "    \n",
    "    # Reconstituer chunk\n",
    "    processed = pd.concat([X, y], axis=1)\n",
    "    \n",
    "    # Split 70% train / 30% test\n",
    "    mask = np.random.rand(len(processed)) < 0.7\n",
    "    train_parts.append(processed[mask])\n",
    "    test_parts.append(processed[~mask])\n",
    "\n",
    "# --- Concaténer tous les chunks ---\n",
    "train_df = pd.concat(train_parts, ignore_index=True)\n",
    "test_df = pd.concat(test_parts, ignore_index=True)\n",
    "\n",
    "print(\"Train set :\", train_df.shape)\n",
    "print(\"Test set :\", test_df.shape)\n",
    "\n",
    "# --- Séparer X / y ---\n",
    "X_train = train_df.drop(columns=[\"fire\"]).values\n",
    "y_train = train_df[\"fire\"].values\n",
    "X_test = test_df.drop(columns=[\"fire\"]).values\n",
    "y_test = test_df[\"fire\"].values\n",
    "\n",
    "# --- Random Forest From Scratch ---\n",
    "rf = RandomForestScratch(n_trees=20, max_depth=8, min_samples_split=20)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# --- Prédictions ---\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# --- Résultats ---\n",
    "print(\"\\n=== RANDOM FOREST FROM SCRATCH ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbd1af45",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 158\u001b[0m\n\u001b[0;32m    156\u001b[0m         idxs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(X_values), \u001b[38;5;28mlen\u001b[39m(X_values), replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    157\u001b[0m         tree \u001b[38;5;241m=\u001b[39m DecisionTreeScratch(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m--> 158\u001b[0m         \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43midxs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43midxs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m         forest_trees\u001b[38;5;241m.\u001b[39mappend(tree)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# Prédictions sur un autre chunk ou échantillon test\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# Exemple : prendre un chunk test\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 84\u001b[0m, in \u001b[0;36mDecisionTreeScratch.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 72\u001b[0m, in \u001b[0;36mDecisionTreeScratch.build_tree\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m     64\u001b[0m node \u001b[38;5;241m=\u001b[39m DecisionTreeNode(\n\u001b[0;32m     65\u001b[0m     gini\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgini(y),\n\u001b[0;32m     66\u001b[0m     num_samples\u001b[38;5;241m=\u001b[39my\u001b[38;5;241m.\u001b[39msize,\n\u001b[0;32m     67\u001b[0m     num_samples_per_class\u001b[38;5;241m=\u001b[39mnum_samples_per_class,\n\u001b[0;32m     68\u001b[0m     predicted_class\u001b[38;5;241m=\u001b[39mpredicted_class,\n\u001b[0;32m     69\u001b[0m )\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m depth \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_split:\n\u001b[1;32m---> 72\u001b[0m     idx, thr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m         indices_left \u001b[38;5;241m=\u001b[39m X[:, idx] \u001b[38;5;241m<\u001b[39m thr\n",
      "Cell \u001b[1;32mIn[1], line 50\u001b[0m, in \u001b[0;36mDecisionTreeScratch.best_split\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     48\u001b[0m num_left[c] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     49\u001b[0m num_right[c] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 50\u001b[0m gini_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_left\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnum_left\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m gini_right \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28msum\u001b[39m((num_right[x]\u001b[38;5;241m/\u001b[39m(m\u001b[38;5;241m-\u001b[39mi))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m num_right)\n\u001b[0;32m     52\u001b[0m gini_total \u001b[38;5;241m=\u001b[39m (i\u001b[38;5;241m*\u001b[39mgini_left \u001b[38;5;241m+\u001b[39m (m\u001b[38;5;241m-\u001b[39mi)\u001b[38;5;241m*\u001b[39mgini_right)\u001b[38;5;241m/\u001b[39mm\n",
      "Cell \u001b[1;32mIn[1], line 50\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     48\u001b[0m num_left[c] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     49\u001b[0m num_right[c] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 50\u001b[0m gini_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28msum\u001b[39m((\u001b[43mnum_left\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m/\u001b[39mi)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m num_left)\n\u001b[0;32m     51\u001b[0m gini_right \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28msum\u001b[39m((num_right[x]\u001b[38;5;241m/\u001b[39m(m\u001b[38;5;241m-\u001b[39mi))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m num_right)\n\u001b[0;32m     52\u001b[0m gini_total \u001b[38;5;241m=\u001b[39m (i\u001b[38;5;241m*\u001b[39mgini_left \u001b[38;5;241m+\u001b[39m (m\u001b[38;5;241m-\u001b[39mi)\u001b[38;5;241m*\u001b[39mgini_right)\u001b[38;5;241m/\u001b[39mm\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from collections import Counter\n",
    "\n",
    "# ---------------------------\n",
    "# Random Tree / Random Forest From Scratch\n",
    "# ---------------------------\n",
    "\n",
    "class DecisionTreeNode:\n",
    "    def __init__(self, gini=None, num_samples=None, num_samples_per_class=None,\n",
    "                 predicted_class=None, feature_index=None, threshold=None,\n",
    "                 left=None, right=None):\n",
    "        self.gini = gini\n",
    "        self.num_samples = num_samples\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.predicted_class = predicted_class\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "class DecisionTreeScratch:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "\n",
    "    def gini(self, y):\n",
    "        m = len(y)\n",
    "        return 1.0 - sum((np.sum(y == c) / m) ** 2 for c in np.unique(y))\n",
    "\n",
    "    def best_split(self, X, y):\n",
    "        m, n = X.shape\n",
    "        if m <= 1:\n",
    "            return None, None\n",
    "\n",
    "        parent_gini = self.gini(y)\n",
    "        best_gini = 1.0\n",
    "        best_idx, best_thr = None, None\n",
    "\n",
    "        for idx in range(n):\n",
    "            thresholds, classes = zip(*sorted(zip(X[:, idx], y)))\n",
    "            num_left = [0] * len(np.unique(y))\n",
    "            num_right = Counter(classes)\n",
    "            for i in range(1, m):\n",
    "                c = classes[i-1]\n",
    "                num_left[c] += 1\n",
    "                num_right[c] -= 1\n",
    "                gini_left = 1.0 - sum((num_left[x]/i)**2 for x in num_left)\n",
    "                gini_right = 1.0 - sum((num_right[x]/(m-i))**2 for x in num_right)\n",
    "                gini_total = (i*gini_left + (m-i)*gini_right)/m\n",
    "                if thresholds[i] == thresholds[i-1]:\n",
    "                    continue\n",
    "                if gini_total < best_gini:\n",
    "                    best_gini = gini_total\n",
    "                    best_idx = idx\n",
    "                    best_thr = (thresholds[i] + thresholds[i-1]) / 2\n",
    "        return best_idx, best_thr\n",
    "\n",
    "    def build_tree(self, X, y, depth=0):\n",
    "        num_samples_per_class = [np.sum(y == i) for i in np.unique(y)]\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        node = DecisionTreeNode(\n",
    "            gini=self.gini(y),\n",
    "            num_samples=y.size,\n",
    "            num_samples_per_class=num_samples_per_class,\n",
    "            predicted_class=predicted_class,\n",
    "        )\n",
    "\n",
    "        if depth < self.max_depth and y.size >= self.min_samples_split:\n",
    "            idx, thr = self.best_split(X, y)\n",
    "            if idx is not None:\n",
    "                indices_left = X[:, idx] < thr\n",
    "                X_left, y_left = X[indices_left], y[indices_left]\n",
    "                X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "                node.feature_index = idx\n",
    "                node.threshold = thr\n",
    "                node.left = self.build_tree(X_left, y_left, depth + 1)\n",
    "                node.right = self.build_tree(X_right, y_right, depth + 1)\n",
    "        return node\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self.build_tree(X, y)\n",
    "\n",
    "    def predict_sample(self, x, node):\n",
    "        if node.left is None and node.right is None:\n",
    "            return node.predicted_class\n",
    "        if x[node.feature_index] < node.threshold:\n",
    "            return self.predict_sample(x, node.left)\n",
    "        else:\n",
    "            return self.predict_sample(x, node.right)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.predict_sample(x, self.tree) for x in X])\n",
    "\n",
    "class RandomForestScratch:\n",
    "    def __init__(self, n_trees=10, max_depth=5, min_samples_split=2):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        n_samples = X.shape[0]\n",
    "        for _ in range(self.n_trees):\n",
    "            idxs = np.random.choice(n_samples, n_samples, replace=True)\n",
    "            tree = DecisionTreeScratch(max_depth=self.max_depth,\n",
    "                                       min_samples_split=self.min_samples_split)\n",
    "            tree.fit(X[idxs], y[idxs])\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # vote majoritaire\n",
    "        predictions = np.array([tree.predict(X) for tree in self.trees])\n",
    "        y_pred = []\n",
    "        for i in range(X.shape[0]):\n",
    "            counts = np.bincount(predictions[:, i])\n",
    "            y_pred.append(np.argmax(counts))\n",
    "        return np.array(y_pred)\n",
    "\n",
    "# ---------------------------\n",
    "# Lecture et traitement chunk par chunk\n",
    "# ---------------------------\n",
    "\n",
    "file = r\"C:\\Users\\DELL\\Desktop\\project_fire\\data\\processed\\fire_soil_merged_cleaned.csv\"\n",
    "chunksize = 100000  # plus petit pour réduire la mémoire\n",
    "forest_trees = []\n",
    "n_trees_per_chunk = 5  # exemple\n",
    "\n",
    "# On stocke les arbres de chaque chunk\n",
    "for chunk in pd.read_csv(file, chunksize=chunksize):\n",
    "    if \"geometry\" in chunk.columns:\n",
    "        chunk = chunk.drop(columns=[\"geometry\"])\n",
    "    \n",
    "    X = chunk.drop(columns=[\"fire\"])\n",
    "    y = chunk[\"fire\"]\n",
    "    \n",
    "    # One-hot encoding\n",
    "    cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "    if cat_cols:\n",
    "        X = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
    "    \n",
    "    # Optimisation type\n",
    "    for col in X.select_dtypes(include=['float64']).columns:\n",
    "        X[col] = X[col].astype(np.float32)\n",
    "    for col in X.select_dtypes(include=['int64']).columns:\n",
    "        X[col] = X[col].astype(np.int32)\n",
    "    \n",
    "    X_values = X.values\n",
    "    y_values = y.values\n",
    "\n",
    "    # Créer des arbres pour ce chunk\n",
    "    for _ in range(n_trees_per_chunk):\n",
    "        idxs = np.random.choice(len(X_values), len(X_values), replace=True)\n",
    "        tree = DecisionTreeScratch(max_depth=8, min_samples_split=20)\n",
    "        tree.fit(X_values[idxs], y_values[idxs])\n",
    "        forest_trees.append(tree)\n",
    "\n",
    "# ---------------------------\n",
    "# Prédictions sur un autre chunk ou échantillon test\n",
    "# ---------------------------\n",
    "\n",
    "# Exemple : prendre un chunk test\n",
    "test_chunk = pd.read_csv(file, chunksize=100000)\n",
    "test_df = next(test_chunk)\n",
    "if \"geometry\" in test_df.columns:\n",
    "    test_df = test_df.drop(columns=[\"geometry\"])\n",
    "X_test = test_df.drop(columns=[\"fire\"])\n",
    "y_test = test_df[\"fire\"]\n",
    "\n",
    "cat_cols = X_test.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "if cat_cols:\n",
    "    X_test = pd.get_dummies(X_test, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Adapter colonnes pour match avec le training (si des colonnes manquent)\n",
    "for col in X_test.columns:\n",
    "    if col not in X.columns:\n",
    "        X_test[col] = 0\n",
    "for col in X.columns:\n",
    "    if col not in X_test.columns:\n",
    "        X_test[col] = 0\n",
    "\n",
    "X_test = X_test[X.columns]  # réordonner\n",
    "\n",
    "X_test_values = X_test.values\n",
    "y_test_values = y_test.values\n",
    "\n",
    "# vote majoritaire\n",
    "predictions = np.array([tree.predict(X_test_values) for tree in forest_trees])\n",
    "y_pred = []\n",
    "for i in range(X_test_values.shape[0]):\n",
    "    counts = np.bincount(predictions[:, i])\n",
    "    y_pred.append(np.argmax(counts))\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# ---------------------------\n",
    "# Évaluation\n",
    "# ---------------------------\n",
    "print(classification_report(y_test_values, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_values, y_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test_values, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
